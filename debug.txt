|   8   | action_rate             | -0.0001 |
|   9   | joint_vel_right         | -0.0001 |
|   10  | joint_vel_left          | -0.0001 |
+-------+-------------------------+---------+

[INFO] Curriculum Manager:  <CurriculumManager> contains 0 active terms.
+----------------------+
| Active Curriculum Terms |
+-----------+----------+
|   Index   | Name     |
+-----------+----------+
+-----------+----------+

Creating window for environment.
[INFO]: Completed setting up the environment...
[Play] Observation space: Dict('policy': Dict('cube_1_ori': Box(-inf, inf, (1, 4), float32), 'cube_1_pos': Box(-inf, inf, (1, 3), float32), 'cube_2_ori': Box(-inf, inf, (1, 4), float32), 'cube_2_pos': Box(-inf, inf, (1, 3), float32), 'last_action_all': Box(-inf, inf, (1, 12), float32), 'left_ee_orientation': Box(-inf, inf, (1, 4), float32), 'left_ee_position': Box(-inf, inf, (1, 3), float32), 'left_joint_pos': Box(-inf, inf, (1, 6), float32), 'left_joint_vel': Box(-inf, inf, (1, 6), float32), 'right_ee_orientation': Box(-inf, inf, (1, 4), float32), 'right_ee_position': Box(-inf, inf, (1, 3), float32), 'right_joint_pos': Box(-inf, inf, (1, 6), float32), 'right_joint_vel': Box(-inf, inf, (1, 6), float32)), 'subtask_terms': Dict('pick_cube': Box(-inf, inf, (1,), float32), 'stack_cube': Box(-inf, inf, (1,), float32)))
[Play] Action space: Box(-inf, inf, (1, 12), float32)
[Play] Obs dim: 64, Action dim: 12

[Play] Loading policy from: ./logs/graph_unet_full/stack_joint_flow_matching/1000inject/checkpoint_600.pt
[Play] Policy type: DualArmUnetPolicy
[GraphDiTPolicy] Loaded model from: ./logs/graph_unet_full/stack_joint_flow_matching/1000inject/checkpoint_600.pt
[Play] Using Graph-Unet for all action dimensions (including gripper)
[Play] Policy mode: FLOW_MATCHING
[Play] Loaded observation normalization stats
[Play] Loaded action normalization stats
[Play] Loaded node feature normalization stats
[Play] Loaded joint state normalization stats
[Play] Loaded obs_key_offsets for dynamic extraction
[Play] Using 4-node graph (node_histories)

[Play] Running 1000 episodes...
[Play] Action history length: 10
[Play] ACTION CHUNKING: pred_horizon=20, exec_horizon=10
[Play] Inference frequency: every 10 steps (vs every step without chunking)
[Play] Phase condition: 2 subtasks (pick/stack), signal will be injected
[Play] Gripper: continuous (raw)
[Play] Success: timeout=失败, 否则 height>=0.1m=成功 (与 play_graph_rl 一致)
[Play] EMA smoothing enabled: alpha=1.0 (joints only, gripper excluded)
Traceback (most recent call last):
  File "/mnt/ssd/dual_isaac_so_arm101/scripts/graph_unet/play.py", line 1253, in <module>
    main()
  File "/mnt/ssd/dual_isaac_so_arm101/scripts/graph_unet/play.py", line 1239, in main
    play_graph_unet_policy(
  File "/mnt/ssd/dual_isaac_so_arm101/scripts/graph_unet/play.py", line 635, in play_graph_unet_policy
    obs_tensor_raw = torch.tensor(obs_val, device=device)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Could not infer dtype of dict
