# Isaac Lab Robomimic æ¨¡ä»¿å­¦ä¹ è®­ç»ƒæŒ‡å—

## ğŸ“š æ¦‚è¿°

Isaac Lab ä½¿ç”¨ **Robomimic** æ¡†æ¶è¿›è¡Œæ¨¡ä»¿å­¦ä¹ ï¼ˆImitation Learningï¼‰è®­ç»ƒã€‚è¿™ä¸ªæŒ‡å—åŸºäº Isaac Lab å®˜æ–¹å®ç°ï¼Œå±•ç¤ºå¦‚ä½•ä¸ºä½ çš„ä»»åŠ¡è®¾ç½® BC (Behavioral Cloning) è®­ç»ƒã€‚

---

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### 1. è®­ç»ƒè„šæœ¬

**ä½ç½®**: `/mnt/ssd/IsaacLab/scripts/imitation_learning/robomimic/train.py`

**ä¸»è¦åŠŸèƒ½**:
- åŠ è½½ HDF5 æ•°æ®é›†
- ä½¿ç”¨ Robomimic ç®—æ³•ï¼ˆå¦‚ BCï¼‰è®­ç»ƒ Policy
- æ”¯æŒè§‚æµ‹å½’ä¸€åŒ–å’ŒåŠ¨ä½œå½’ä¸€åŒ–
- è‡ªåŠ¨ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹

**å…³é”®æµç¨‹**:
```
1. åŠ è½½æ•°æ®é›† (HDF5)
2. åˆ›å»ºç¯å¢ƒ
3. åˆå§‹åŒ– Robomimic æ¨¡å‹
4. è®­ç»ƒå¾ªç¯
5. ä¿å­˜æ£€æŸ¥ç‚¹
```

### 2. é…ç½®æ–‡ä»¶æ ¼å¼ (JSON)

**ä½ç½®**: `source/SO_100/SO_100/tasks/pick_place/agents/robomimic/bc.json`

**ç»“æ„**:
```json
{
    "algo_name": "bc",              // ç®—æ³•åç§°
    "experiment": {                 // å®éªŒé…ç½®
        "name": "bc_experiment",
        "validate": true,
        "save": { ... }
    },
    "train": {                      // è®­ç»ƒé…ç½®
        "data": null,               // æ•°æ®é›†è·¯å¾„ï¼ˆå¯é€šè¿‡å‘½ä»¤è¡Œè¦†ç›–ï¼‰
        "batch_size": 100,
        "num_epochs": 2000,
        "seq_length": 10
    },
    "algo": {                       // ç®—æ³•ç‰¹å®šé…ç½®
        "optim_params": { ... },
        "loss": { ... },
        "actor_layer_dims": [512, 512],  // ç½‘ç»œç»“æ„
        "rnn": { ... }              // RNN é…ç½®ï¼ˆå¯é€‰ï¼‰
    },
    "observation": {                // è§‚æµ‹é…ç½®
        "modalities": {
            "obs": {
                "low_dim": ["joint_pos", "joint_vel", "object", ...]
            }
        }
    }
}
```

---

## ğŸ“ æ­¥éª¤ 1: åˆ›å»º Robomimic é…ç½®æ–‡ä»¶

### åˆ›å»ºé…ç½®æ–‡ä»¶ç›®å½•

```bash
mkdir -p source/SO_100/SO_100/tasks/pick_place/agents/robomimic
```

### åˆ›å»º BC é…ç½®æ–‡ä»¶

åˆ›å»ºæ–‡ä»¶: `source/SO_100/SO_100/tasks/pick_place/agents/robomimic/bc_rnn_low_dim.json`

```json
{
    "algo_name": "bc",
    "experiment": {
        "name": "bc_rnn_pick_place",
        "validate": false,
        "logging": {
            "terminal_output_to_txt": true,
            "log_tb": true
        },
        "save": {
            "enabled": true,
            "every_n_epochs": 100,
            "on_best_rollout_success_rate": true
        },
        "epoch_every_n_steps": 100,
        "env": null,
        "render": false,
        "render_video": false
    },
    "train": {
        "data": null,
        "num_data_workers": 4,
        "hdf5_cache_mode": "all",
        "hdf5_normalize_obs": false,
        "seq_length": 10,
        "dataset_keys": ["actions"],
        "cuda": true,
        "batch_size": 100,
        "num_epochs": 2000,
        "seed": 101
    },
    "algo": {
        "optim_params": {
            "policy": {
                "optimizer_type": "adam",
                "learning_rate": {
                    "initial": 0.001,
                    "decay_factor": 0.1,
                    "epoch_schedule": [],
                    "scheduler_type": "multistep"
                },
                "regularization": {
                    "L2": 0.0
                }
            }
        },
        "loss": {
            "l2_weight": 1.0,
            "l1_weight": 0.0,
            "cos_weight": 0.0
        },
        "actor_layer_dims": [512, 512],
        "rnn": {
            "enabled": true,
            "horizon": 10,
            "hidden_dim": 400,
            "rnn_type": "LSTM",
            "num_layers": 2,
            "open_loop": false
        }
    },
    "observation": {
        "modalities": {
            "obs": {
                "low_dim": [
                    "actions",
                    "joint_pos",
                    "joint_vel",
                    "object",
                    "object_positions",
                    "object_orientations",
                    "eef_pos",
                    "eef_quat",
                    "gripper_pos"
                ],
                "rgb": [],
                "depth": [],
                "scan": []
            }
        }
    }
}
```

---

## ğŸ“ æ­¥éª¤ 2: æ³¨å†Œ Robomimic é…ç½®åˆ°ç¯å¢ƒ

åœ¨ç¯å¢ƒæ³¨å†Œæ—¶æ·»åŠ  `robomimic_bc_cfg_entry_point`:

**æ–‡ä»¶**: `source/SO_100/SO_100/tasks/pick_place/__init__.py`

```python
from . import agents

gym.register(
    id="SO-ARM100-Pick-Place-DualArm-IK-Abs-v0",
    entry_point=_ENTRY_POINT_ABS,
    kwargs={
        "env_cfg_entry_point": _ENV_CFG_ABS,
        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:PPORunnerCfg",
        "robomimic_bc_cfg_entry_point": f"{agents.__name__}:robomimic/bc_rnn_low_dim.json",  # æ·»åŠ è¿™è¡Œ
    },
    disable_env_checker=True,
)
```

**æ³¨æ„**: 
- `robomimic_bc_cfg_entry_point` æ ¼å¼: `{agents.__name__}:robomimic/{config_file}`
- è·¯å¾„ç›¸å¯¹äº `agents` æ¨¡å—

---

## ğŸ“ æ­¥éª¤ 3: æ•°æ®é›†å‡†å¤‡

### HDF5 æ•°æ®é›†æ ¼å¼

ä½ çš„æ•°æ®é›†åº”è¯¥åŒ…å«ä»¥ä¸‹ç»“æ„:

```
/data/
  /demo_0/
    /observations/
      /actions: (N, 8)  # IK Absolute actions [x, y, z, qw, qx, qy, qz, gripper]
      /joint_pos: (N, 5)
      /joint_vel: (N, 5)
      /object: (N, 27)
      ...
    /actions: (N, 8)  # ä¸»è¦ actions
    /rewards: (N,)
    /dones: (N,)
  /demo_1/
    ...
```

### è§‚æµ‹é”®åæ˜ å°„

é…ç½®æ–‡ä»¶ä¸­çš„ `observation.modalities.obs.low_dim` éœ€è¦ä¸æ•°æ®é›†ä¸­çš„é”®ååŒ¹é…ã€‚

**å¸¸ç”¨æ˜ å°„**:
- `joint_pos` â†’ å¯¹åº”æ•°æ®é›†çš„ `joint_pos`
- `joint_vel` â†’ å¯¹åº”æ•°æ®é›†çš„ `joint_vel`
- `object` â†’ å¯¹åº”æ•°æ®é›†çš„ `object`
- `eef_pos` â†’ å¯¹åº”æ•°æ®é›†çš„ `eef_pos`
- `eef_quat` â†’ å¯¹åº”æ•°æ®é›†çš„ `eef_quat`
- `gripper_pos` â†’ å¯¹åº”æ•°æ®é›†çš„ `gripper_pos`

---

## ğŸš€ æ­¥éª¤ 4: å¼€å§‹è®­ç»ƒ

### è®­ç»ƒå‘½ä»¤

```bash
./isaaclab.sh -p scripts/imitation_learning/robomimic/train.py \
    --task SO-ARM100-Pick-Place-DualArm-IK-Abs-v0 \
    --algo bc \
    --normalize_training_actions \
    --dataset ./datasets/generated_dataset_pick_place.hdf5 \
    --log_dir robomimic \
    --epochs 2000
```

### å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--task` | ç¯å¢ƒä»»åŠ¡åç§° | `SO-ARM100-Pick-Place-DualArm-IK-Abs-v0` |
| `--algo` | ç®—æ³•åç§° | `bc` (Behavioral Cloning) |
| `--dataset` | HDF5 æ•°æ®é›†è·¯å¾„ | `./datasets/my_dataset.hdf5` |
| `--normalize_training_actions` | å½’ä¸€åŒ– actions åˆ° [-1, 1] | æ ‡å¿—ä½ |
| `--log_dir` | æ—¥å¿—ç›®å½• | `robomimic` |
| `--epochs` | è®­ç»ƒè½®æ•° | `2000` |

---

## ğŸ“Š é…ç½®æ–‡ä»¶å…³é”®å‚æ•°è¯´æ˜

### ç½‘ç»œç»“æ„ (`algo.actor_layer_dims`)

```json
"actor_layer_dims": [512, 512]  // å…¨è¿æ¥å±‚ç»´åº¦
```

### RNN é…ç½® (`algo.rnn`)

```json
"rnn": {
    "enabled": true,           // å¯ç”¨ RNN
    "horizon": 10,             // åºåˆ—é•¿åº¦
    "hidden_dim": 400,         // éšè—å±‚ç»´åº¦
    "rnn_type": "LSTM",        // ç±»å‹: "LSTM" æˆ– "GRU"
    "num_layers": 2            // RNN å±‚æ•°
}
```

### è®­ç»ƒå‚æ•° (`train`)

```json
"train": {
    "batch_size": 100,         // æ‰¹æ¬¡å¤§å°
    "num_epochs": 2000,        // è®­ç»ƒè½®æ•°
    "seq_length": 10,          // åºåˆ—é•¿åº¦ï¼ˆä¸ RNN horizon ä¸€è‡´ï¼‰
    "learning_rate": {         // å­¦ä¹ ç‡
        "initial": 0.001
    }
}
```

---

## ğŸ” è§‚æµ‹é”®åé…ç½®

### å…³é”®ç‚¹

é…ç½®æ–‡ä»¶ä¸­çš„è§‚æµ‹é”®åå¿…é¡»ä¸ï¼š
1. **HDF5 æ•°æ®é›†ä¸­çš„é”®å**åŒ¹é…
2. **ç¯å¢ƒçš„è§‚æµ‹ç©ºé—´**åŒ¹é…

### æ£€æŸ¥è§‚æµ‹é”®å

ä½ çš„ç¯å¢ƒè§‚æµ‹é”®ååœ¨ `pick_place_env_cfg.py` ä¸­å®šä¹‰:

```python
class PolicyCfg(ObsGroup):
    actions = ObsTerm(func=mdp.last_action)
    joint_pos = ObsTerm(func=mdp.joint_pos_rel)
    joint_vel = ObsTerm(func=mdp.joint_vel_rel)
    object = ObsTerm(func=mdp.object_obs)
    object_positions = ObsTerm(func=mdp.object_positions_in_world_frame)
    object_orientations = ObsTerm(func=mdp.object_orientations_in_world_frame)
    eef_pos = ObsTerm(func=mdp.ee_frame_pos)
    eef_quat = ObsTerm(func=mdp.ee_frame_quat)
    gripper_pos = ObsTerm(func=mdp.gripper_pos)
```

è¿™äº›é”®åéœ€è¦åœ¨ JSON é…ç½®æ–‡ä»¶çš„ `observation.modalities.obs.low_dim` ä¸­åˆ—å‡ºã€‚

---

## ğŸ“ æ–‡ä»¶ç»“æ„ç¤ºä¾‹

```
source/SO_100/SO_100/tasks/pick_place/
â”œâ”€â”€ __init__.py                    # æ³¨å†Œç¯å¢ƒï¼ˆæ·»åŠ  robomimic_bc_cfg_entry_pointï¼‰
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rsl_rl_ppo_cfg.py         # RL é…ç½®
â”‚   â””â”€â”€ robomimic/                 # Robomimic é…ç½®ç›®å½•
â”‚       â”œâ”€â”€ bc_rnn_low_dim.json    # BC with RNN é…ç½®
â”‚       â””â”€â”€ bc.json                 # ç®€å• BC é…ç½®
â””â”€â”€ ...
```

---

## ğŸ¯ è®­ç»ƒæµç¨‹æ€»ç»“

```
1. æ”¶é›†æ¼”ç¤ºæ•°æ® â†’ record_demos.py
   â†“
2. ç”Ÿæˆ HDF5 æ•°æ®é›† â†’ datasets/pick_place.hdf5
   â†“
3. åˆ›å»º Robomimic é…ç½®æ–‡ä»¶ â†’ agents/robomimic/bc.json
   â†“
4. æ³¨å†Œé…ç½®åˆ°ç¯å¢ƒ â†’ __init__.py
   â†“
5. å¼€å§‹è®­ç»ƒ â†’ scripts/imitation_learning/robomimic/train.py
   â†“
6. æ¨¡å‹ä¿å­˜åœ¨ â†’ logs/robomimic/SO-ARM100-Pick-Place-DualArm-IK-Abs-v0/.../models/
```

---

## ğŸ”— å‚è€ƒèµ„æº

1. **Isaac Lab Robomimic æ–‡æ¡£**:
   - `/mnt/ssd/IsaacLab/scripts/imitation_learning/robomimic/train.py`
   - `/mnt/ssd/IsaacLab/source/isaaclab_tasks/isaaclab_tasks/manager_based/manipulation/pick_place/`

2. **Robomimic å®˜æ–¹æ–‡æ¡£**:
   - https://robomimic.github.io/

3. **ç¤ºä¾‹é…ç½®æ–‡ä»¶**:
   - `/mnt/ssd/IsaacLab/source/isaaclab_tasks/.../agents/robomimic/bc_rnn_low_dim.json`

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **è§‚æµ‹é”®ååŒ¹é…**: ç¡®ä¿é…ç½®æ–‡ä»¶ä¸­çš„è§‚æµ‹é”®åä¸æ•°æ®é›†å’Œç¯å¢ƒåŒ¹é…
2. **Action å½’ä¸€åŒ–**: ä½¿ç”¨ `--normalize_training_actions` æ—¶ï¼Œactions ä¼šè¢«å½’ä¸€åŒ–åˆ° [-1, 1]
3. **åºåˆ—é•¿åº¦**: `seq_length` å’Œ `rnn.horizon` åº”è¯¥ä¸€è‡´ï¼ˆå¦‚æœä½¿ç”¨ RNNï¼‰
4. **æ•°æ®é›†è·¯å¾„**: å¯ä»¥ä½¿ç”¨ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„

---

ç¥ä½ è®­ç»ƒé¡ºåˆ©ï¼ğŸš€


