# Isaac Lab å›¾åƒå½•åˆ¶å’Œå­˜å‚¨æŒ‡å—

## ğŸ“š æ¦‚è¿°

Isaac Lab æ”¯æŒå½•åˆ¶ç›¸æœºå›¾åƒè§‚æµ‹å¹¶å­˜å‚¨åˆ° HDF5 æ•°æ®é›†ä¸­ã€‚æœ¬æŒ‡å—å±•ç¤ºå¦‚ä½•ï¼š
1. é…ç½®ç›¸æœºä¼ æ„Ÿå™¨
2. æ·»åŠ å›¾åƒè§‚æµ‹åˆ°ç¯å¢ƒ
3. å½•åˆ¶å’Œå­˜å‚¨å›¾åƒæ•°æ®

---

## ğŸ¯ æ­¥éª¤ 1: åœ¨ç¯å¢ƒä¸­æ·»åŠ ç›¸æœºä¼ æ„Ÿå™¨

### 1.1 åœ¨ç¯å¢ƒé…ç½®ä¸­æ·»åŠ ç›¸æœº

**æ–‡ä»¶**: `source/SO_100/SO_100/tasks/pick_place/pick_place_env_cfg.py`

```python
from isaaclab.sensors import CameraCfg
from omni.isaac.lab.sim import PinholeCameraCfg
from omni.isaac.lab.utils import configclass

@configclass
class PickPlaceEnvCfg(ManagerBasedRLEnvCfg):
    # ... å…¶ä»–é…ç½® ...
    
    # æ·»åŠ ç›¸æœºä¼ æ„Ÿå™¨
    camera_front = CameraCfg(
        data_types=["rgb"],  # æˆ– ["rgb", "distance_to_image_plane"]
        spawn=PinholeCameraCfg(
            focal_length=24.0,  # mm
            focus_distance=400.0,  # mm
            horizontal_aperture=20.955,  # mm
            clipping_range=(0.1, 1.0e5),
        ),
        offset=CameraCfg.OffsetCfg(
            pos=(0.5, 0.0, 0.5),  # ç›¸æœºä½ç½® (x, y, z)
            rot=(0.5, -0.5, 0.5, -0.5),  # å››å…ƒæ•° (w, x, y, z)
            convention="ros",
        ),
        prim_path="{ENV_REGEX_NS}/World/origin/front_camera",
        debug_vis=True,
    )
    
    # å¯é€‰ï¼šæ·»åŠ è…•éƒ¨ç›¸æœº
    camera_wrist = CameraCfg(
        data_types=["rgb"],
        spawn=PinholeCameraCfg(
            focal_length=24.0,
            focus_distance=400.0,
            horizontal_aperture=20.955,
            clipping_range=(0.1, 1.0e5),
        ),
        offset=CameraCfg.OffsetCfg(
            pos=(0.0, 0.0, 0.0),
            rot=(1.0, 0.0, 0.0, 0.0),
            convention="ros",
        ),
        prim_path="{ENV_REGEX_NS}/Robot/wrist_2_link/camera_wrist",
        debug_vis=False,
    )
```

---

## ğŸ¯ æ­¥éª¤ 2: æ·»åŠ å›¾åƒè§‚æµ‹åˆ°è§‚æµ‹é…ç½®

### 2.1 åˆ›å»ºå›¾åƒè§‚æµ‹ç»„

**æ–‡ä»¶**: `source/SO_100/SO_100/tasks/pick_place/pick_place_env_cfg.py`

```python
from isaaclab.envs.mdp import ObsTerm

@configclass
class ObservationsCfg:
    @configclass
    class PolicyCfg(ObsGroup):
        # ... ä½ç»´è§‚æµ‹ ...
        joint_pos = ObsTerm(func=mdp.joint_pos_rel)
        joint_vel = ObsTerm(func=mdp.joint_vel_rel)
        eef_pos = ObsTerm(func=mdp.ee_frame_pos)
        eef_quat = ObsTerm(func=mdp.ee_frame_quat)
        # ...
    
    @configclass
    class RGBCameraPolicyCfg(ObsGroup):
        """åŒ…å« RGB å›¾åƒçš„è§‚æµ‹ç»„"""
        
        # å‰ç½®ç›¸æœºå›¾åƒ
        image_front = ObsTerm(
            func=mdp.generated_commands,  # å ä½ç¬¦ï¼Œå®é™…ä½¿ç”¨ç›¸æœºæ•°æ®
            params={
                "asset_cfg": SceneEntityCfg("camera_front"),
                "command_name": "rgb",
            },
        )
        
        # è…•éƒ¨ç›¸æœºå›¾åƒï¼ˆå¯é€‰ï¼‰
        image_wrist = ObsTerm(
            func=mdp.generated_commands,
            params={
                "asset_cfg": SceneEntityCfg("camera_wrist"),
                "command_name": "rgb",
            },
        )
        
        # ä»ç„¶åŒ…å«ä½ç»´è§‚æµ‹
        joint_pos = ObsTerm(func=mdp.joint_pos_rel)
        joint_vel = ObsTerm(func=mdp.joint_vel_rel)
        eef_pos = ObsTerm(func=mdp.ee_frame_pos)
        eef_quat = ObsTerm(func=mdp.ee_frame_quat)

@configclass
class PickPlaceEnvCfg(ManagerBasedRLEnvCfg):
    # ... å…¶ä»–é…ç½® ...
    
    # ä½¿ç”¨åŒ…å«å›¾åƒçš„è§‚æµ‹é…ç½®
    observations = ObservationsCfg()
    observations.policy = ObservationsCfg.RGBCameraPolicyCfg()
```

### 2.2 å®é™…è·å–ç›¸æœºæ•°æ®ï¼ˆæ¨èæ–¹æ³•ï¼‰

æ›´å¥½çš„æ–¹æ³•æ˜¯ç›´æ¥ä»ç›¸æœºä¼ æ„Ÿå™¨è¯»å–ï¼š

```python
@configclass
class ObservationsCfg:
    @configclass
    class RGBCameraPolicyCfg(ObsGroup):
        """åŒ…å« RGB å›¾åƒçš„è§‚æµ‹ç»„"""
        
        # ç›´æ¥ä»ç›¸æœºä¼ æ„Ÿå™¨è¯»å– RGB å›¾åƒ
        image_front = ObsTerm(
            func=lambda env: env.scene["camera_front"].data.rgb,  # ç›´æ¥è®¿é—®ç›¸æœºæ•°æ®
        )
        
        # æˆ–ä½¿ç”¨ç¯å¢ƒè¾…åŠ©å‡½æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        # image_front = ObsTerm(
        #     func=mdp.image_from_camera,
        #     params={"camera_name": "camera_front"},
        # )
        
        # ä½ç»´è§‚æµ‹
        joint_pos = ObsTerm(func=mdp.joint_pos_rel)
        joint_vel = ObsTerm(func=mdp.joint_vel_rel)
        # ...
```

---

## ğŸ¯ æ­¥éª¤ 3: HDF5 æ•°æ®é›†ä¸­çš„å›¾åƒå­˜å‚¨æ ¼å¼

### 3.1 HDF5 æ•°æ®é›†ç»“æ„ï¼ˆåŒ…å«å›¾åƒï¼‰

```
dataset.hdf5
â””â”€â”€ data/
    â”œâ”€â”€ demo_0/
    â”‚   â”œâ”€â”€ observations/
    â”‚   â”‚   â”œâ”€â”€ image_front: (N, H, W, 3)      # RGB å›¾åƒ [0-255]
    â”‚   â”‚   â”œâ”€â”€ image_wrist: (N, H, W, 3)      # RGB å›¾åƒ [0-255]
    â”‚   â”‚   â”œâ”€â”€ joint_pos: (N, num_joints)
    â”‚   â”‚   â”œâ”€â”€ joint_vel: (N, num_joints)
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”œâ”€â”€ actions: (N, action_dim)
    â”‚   â”œâ”€â”€ rewards: (N,)
    â”‚   â””â”€â”€ dones: (N,)
    â””â”€â”€ ...
```

### 3.2 å›¾åƒæ•°æ®æ ¼å¼

- **æ•°æ®ç±»å‹**: `uint8` (0-255)
- **å½¢çŠ¶**: `[num_steps, height, width, channels]`
- **é€šé“é¡ºåº**: RGB (æœ€åä¸€ä¸ªç»´åº¦)
- **å­˜å‚¨æ ¼å¼**: HDF5 æ•°ç»„

---

## ğŸ“ å®Œæ•´ç¤ºä¾‹ï¼šæ·»åŠ ç›¸æœºåˆ° Pick-Place ç¯å¢ƒ

### ç¤ºä¾‹ 1: æ·»åŠ å‰ç½®ç›¸æœº

**æ–‡ä»¶**: `source/SO_100/SO_100/tasks/pick_place/pick_place_ik_abs_env_cfg.py`

```python
from isaaclab.sensors import CameraCfg
from omni.isaac.lab.sim import PinholeCameraCfg
from omni.isaac.lab.utils import configclass

@configclass
class PickPlaceIKAbsEnvCfg(ManagerBasedRLEnvCfg):
    # ... åœºæ™¯é…ç½® ...
    
    # æ·»åŠ ç›¸æœº
    camera_front = CameraCfg(
        data_types=["rgb"],
        spawn=PinholeCameraCfg(
            focal_length=24.0,
            focus_distance=400.0,
            horizontal_aperture=20.955,
            clipping_range=(0.1, 1.0e5),
            resolution=(224, 224),  # å›¾åƒåˆ†è¾¨ç‡ (height, width)
        ),
        offset=CameraCfg.OffsetCfg(
            pos=(0.5, 0.0, 0.5),  # ç›¸æœºä½ç½®
            rot=(0.5, -0.5, 0.5, -0.5),  # å››å…ƒæ•°
            convention="ros",
        ),
        prim_path="{ENV_REGEX_NS}/World/origin/front_camera",
        debug_vis=True,
    )
    
    # è§‚æµ‹é…ç½®
    @configclass
    class ObservationsCfg:
        @configclass
        class PolicyCfg(ObsGroup):
            # å›¾åƒè§‚æµ‹
            image_front = ObsTerm(
                func=lambda env: env.scene["camera_front"].data.rgb,
            )
            
            # ä½ç»´è§‚æµ‹
            joint_pos = ObsTerm(func=mdp.joint_pos_rel)
            joint_vel = ObsTerm(func=mdp.joint_vel_rel)
            eef_pos = ObsTerm(func=mdp.ee_frame_pos)
            eef_quat = ObsTerm(func=mdp.ee_frame_quat)
            object = ObsTerm(func=mdp.object_obs)
            gripper_pos = ObsTerm(func=mdp.gripper_pos)
```

### ç¤ºä¾‹ 2: ä½¿ç”¨è‡ªå®šä¹‰è§‚æµ‹å‡½æ•°

å¦‚æœä½ éœ€è¦é¢„å¤„ç†å›¾åƒï¼ˆä¾‹å¦‚å½’ä¸€åŒ–ã€è£å‰ªç­‰ï¼‰ï¼š

**æ–‡ä»¶**: `source/SO_100/SO_100/tasks/pick_place/mdp/observations.py`

```python
import torch

def camera_rgb_image(
    env: ManagerBasedRLEnv,
    camera_name: str = "camera_front",
) -> torch.Tensor:
    """è·å–ç›¸æœº RGB å›¾åƒè§‚æµ‹.
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        camera_name: ç›¸æœºåç§°
        
    Returns:
        RGB å›¾åƒå¼ é‡ [num_envs, H, W, 3], å€¼èŒƒå›´ [0-255]
    """
    # ä»åœºæ™¯ä¸­è·å–ç›¸æœº
    camera = env.scene[camera_name]
    
    # è·å– RGB å›¾åƒ
    rgb = camera.data.rgb  # [num_envs, H, W, 3]
    
    # å¯é€‰ï¼šé¢„å¤„ç†
    # - å½’ä¸€åŒ–åˆ° [0, 1]: rgb = rgb / 255.0
    # - è½¬æ¢ä¸º [0, 1] å¹¶è½¬ç½®é€šé“: rgb = rgb.permute(0, 3, 1, 2) / 255.0
    # - è£å‰ª: rgb = rgb[:, :, :224, :224]
    
    return rgb
```

ç„¶ååœ¨é…ç½®ä¸­ä½¿ç”¨ï¼š

```python
@configclass
class ObservationsCfg:
    @configclass
    class PolicyCfg(ObsGroup):
        image_front = ObsTerm(
            func=mdp.camera_rgb_image,
            params={"camera_name": "camera_front"},
        )
```

---

## ğŸ”§ å½•åˆ¶å›¾åƒæ•°æ®

### ä½¿ç”¨ record_demos.py å½•åˆ¶

ä¸€æ—¦ç¯å¢ƒé…ç½®äº†ç›¸æœºå’Œå›¾åƒè§‚æµ‹ï¼Œ`record_demos.py` ä¼šè‡ªåŠ¨å°†å›¾åƒæ•°æ®ä¿å­˜åˆ° HDF5ï¼š

```bash
python scripts/record_demos.py \
    --task SO-ARM100-Pick-Place-DualArm-IK-Abs-v0 \
    --teleop_device keyboard \
    --dataset_file ./datasets/pick_place_with_images.hdf5 \
    --step_hz 30 \
    --num_demos 10
```

### å½•åˆ¶è„šæœ¬ä¼šè‡ªåŠ¨ï¼š

1. **æ£€æµ‹å›¾åƒè§‚æµ‹**: è‡ªåŠ¨æ£€æµ‹è§‚æµ‹ç©ºé—´ä¸­çš„å›¾åƒé”®
2. **å­˜å‚¨åˆ° HDF5**: å›¾åƒä½œä¸º `uint8` æ•°ç»„å­˜å‚¨åœ¨ `observations/` ç»„ä¸­
3. **ä¿æŒå½¢çŠ¶**: å›¾åƒä¿æŒåŸå§‹å½¢çŠ¶ `[N, H, W, 3]`

---

## ğŸ“– è¯»å–åŒ…å«å›¾åƒçš„æ•°æ®é›†

### æ–¹æ³• 1: ä½¿ç”¨ inspect è„šæœ¬

```bash
python scripts/inspect_hdf5_dataset.py \
    --dataset ./datasets/pick_place_with_images.hdf5 \
    --demo_idx 0 \
    --show_samples 3
```

### æ–¹æ³• 2: ç›´æ¥è¯»å– HDF5

```python
import h5py
import numpy as np
from PIL import Image

with h5py.File('dataset_with_images.hdf5', 'r') as f:
    demo_key = 'demo_0'
    demo = f[f'data/{demo_key}']
    
    # è¯»å–å›¾åƒ
    images = np.array(demo['observations/image_front'])  # [N, H, W, 3]
    print(f"Images shape: {images.shape}")
    print(f"Images dtype: {images.dtype}")
    print(f"Images range: [{images.min()}, {images.max()}]")
    
    # è¯»å–ç¬¬ä¸€å¸§å›¾åƒ
    first_image = images[0]  # [H, W, 3]
    
    # ä¿å­˜ä¸ºå›¾åƒæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    img = Image.fromarray(first_image.astype(np.uint8))
    img.save('first_frame.png')
    
    # è¯»å–ä½ç»´è§‚æµ‹
    joint_pos = np.array(demo['observations/joint_pos'])
    actions = np.array(demo['actions'])
```

### æ–¹æ³• 3: PyTorch DataLoaderï¼ˆç”¨äºè®­ç»ƒï¼‰

```python
import torch
from torch.utils.data import Dataset, DataLoader
import h5py
import numpy as np

class HDF5ImageDataset(Dataset):
    """åŒ…å«å›¾åƒçš„ HDF5 æ•°æ®é›†"""
    
    def __init__(self, dataset_path, obs_keys, image_keys=['image_front']):
        self.dataset_path = dataset_path
        self.obs_keys = obs_keys  # ä½ç»´è§‚æµ‹é”®
        self.image_keys = image_keys  # å›¾åƒè§‚æµ‹é”®
        
        # é¢„åŠ è½½æ•°æ®
        self._load_data()
    
    def _load_data(self):
        """åŠ è½½æ‰€æœ‰æ•°æ®"""
        with h5py.File(self.dataset_path, 'r') as f:
            data_group = f['data']
            demo_keys = sorted([k for k in data_group.keys() if k.startswith('demo_')])
            
            all_images = {key: [] for key in self.image_keys}
            all_low_dim_obs = []
            all_actions = []
            
            for demo_key in demo_keys:
                demo = data_group[demo_key]
                
                # åŠ è½½å›¾åƒ
                images_dict = {}
                for key in self.image_keys:
                    if key in demo['observations']:
                        images = np.array(demo['observations'][key])  # [N, H, W, 3]
                        all_images[key].append(images)
                
                # åŠ è½½ä½ç»´è§‚æµ‹
                obs_list = []
                for key in self.obs_keys:
                    if key in demo['observations']:
                        obs_val = np.array(demo['observations'][key])
                        if len(obs_val.shape) > 2:
                            obs_val = obs_val.reshape(obs_val.shape[0], -1)
                        obs_list.append(obs_val)
                
                obs_concat = np.concatenate(obs_list, axis=1) if obs_list else np.array([]).reshape(0, 0)
                actions = np.array(demo['actions'])
                
                all_low_dim_obs.append(obs_concat)
                all_actions.append(actions)
            
            # æ‹¼æ¥æ‰€æœ‰æ¼”ç¤º
            self.images = {key: np.concatenate(all_images[key], axis=0) for key in self.image_keys}
            self.low_dim_obs = np.concatenate(all_low_dim_obs, axis=0) if all_low_dim_obs else np.array([]).reshape(0, 0)
            self.actions = np.concatenate(all_actions, axis=0)
    
    def __len__(self):
        return len(self.actions)
    
    def __getitem__(self, idx):
        # è·å–å›¾åƒï¼ˆå½’ä¸€åŒ–åˆ° [0, 1]ï¼‰
        images_dict = {}
        for key in self.image_keys:
            img = self.images[key][idx].astype(np.float32) / 255.0  # [H, W, 3]
            images_dict[key] = torch.from_numpy(img).permute(2, 0, 1)  # [3, H, W]
        
        # è·å–ä½ç»´è§‚æµ‹
        low_dim_obs = torch.from_numpy(self.low_dim_obs[idx]).float() if self.low_dim_obs.size > 0 else torch.tensor([])
        
        # è·å–åŠ¨ä½œ
        action = torch.from_numpy(self.actions[idx]).float()
        
        return {
            'images': images_dict,
            'low_dim_obs': low_dim_obs,
            'action': action,
        }

# ä½¿ç”¨
dataset = HDF5ImageDataset(
    'dataset_with_images.hdf5',
    obs_keys=['joint_pos', 'joint_vel', 'eef_pos', 'eef_quat'],
    image_keys=['image_front']
)

dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# è¿­ä»£
for batch in dataloader:
    images = batch['images']['image_front']  # [batch_size, 3, H, W]
    low_dim_obs = batch['low_dim_obs']  # [batch_size, obs_dim]
    actions = batch['action']  # [batch_size, action_dim]
    # ... è®­ç»ƒä»£ç  ...
```

---

## ğŸ’¡ é‡è¦æç¤º

### 1. å†…å­˜ç®¡ç†

å›¾åƒæ•°æ®å ç”¨å¤§é‡å†…å­˜ï¼š
- **å•å¼ å›¾åƒ**: 224x224x3 = ~150 KB
- **1000 æ­¥**: ~150 MB
- **100 ä¸ªæ¼”ç¤º**: ~15 GB

**å»ºè®®**:
- ä½¿ç”¨è¾ƒå°çš„å›¾åƒåˆ†è¾¨ç‡ï¼ˆå¦‚ 128x128 æˆ– 224x224ï¼‰
- è€ƒè™‘å‹ç¼©æˆ–ä½¿ç”¨å»¶è¿ŸåŠ è½½
- ä½¿ç”¨æ‰¹å¤„ç†è€Œä¸æ˜¯ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®

### 2. æ•°æ®å½’ä¸€åŒ–

è®­ç»ƒå‰é€šå¸¸éœ€è¦å½’ä¸€åŒ–å›¾åƒï¼š

```python
# æ–¹æ³• 1: å½’ä¸€åŒ–åˆ° [0, 1]
images = images.astype(np.float32) / 255.0

# æ–¹æ³• 2: å½’ä¸€åŒ–åˆ° [-1, 1]
images = (images.astype(np.float32) / 255.0) * 2.0 - 1.0

# æ–¹æ³• 3: ImageNet å½’ä¸€åŒ–
mean = np.array([0.485, 0.456, 0.406])
std = np.array([0.229, 0.224, 0.225])
images = (images.astype(np.float32) / 255.0 - mean) / std
```

### 3. é€šé“é¡ºåº

Isaac Lab å­˜å‚¨çš„å›¾åƒæ ¼å¼ï¼š
- **HDF5**: `[N, H, W, 3]` (é€šé“åœ¨æœ€åï¼ŒRGB)
- **PyTorch**: `[N, 3, H, W]` (é€šé“åœ¨å‰)

è½¬æ¢ï¼š

```python
# HDF5 -> PyTorch
img_pytorch = torch.from_numpy(img_hdf5).permute(0, 3, 1, 2)  # [N, H, W, 3] -> [N, 3, H, W]

# PyTorch -> HDF5
img_hdf5 = img_pytorch.permute(0, 2, 3, 1).numpy()  # [N, 3, H, W] -> [N, H, W, 3]
```

### 4. å¤šç›¸æœºæ”¯æŒ

å¯ä»¥æ·»åŠ å¤šä¸ªç›¸æœºï¼š

```python
@configclass
class PickPlaceEnvCfg(ManagerBasedRLEnvCfg):
    camera_front = CameraCfg(...)
    camera_wrist = CameraCfg(...)
    camera_top = CameraCfg(...)
    
    @configclass
    class ObservationsCfg:
        @configclass
        class PolicyCfg(ObsGroup):
            image_front = ObsTerm(...)
            image_wrist = ObsTerm(...)
            image_top = ObsTerm(...)
```

---

## ğŸ”— å‚è€ƒ

1. **Isaac Lab ç›¸æœºæ–‡æ¡£**: `/mnt/ssd/IsaacLab/docs/sensors/camera.md`
2. **robomimic å›¾åƒè®­ç»ƒ**: `/mnt/ssd/IsaacLab/scripts/imitation_learning/robomimic/train.py`
3. **ç¤ºä¾‹ç¯å¢ƒ**: `/mnt/ssd/IsaacLab/source/isaaclab_tasks/.../stack_ik_rel_visuomotor_env_cfg.py`

---

ç¥ä½ å½•åˆ¶é¡ºåˆ©ï¼ğŸš€


