# HDF5 æ•°æ®é›†è¯»å–æŒ‡å—

## ğŸ“š æ¦‚è¿°

Isaac Lab ä½¿ç”¨ HDF5 æ ¼å¼å­˜å‚¨æ¼”ç¤ºæ•°æ®ã€‚æœ¬æŒ‡å—å±•ç¤ºå¦‚ä½•è¯»å–å’Œåˆ†æè¿™äº›æ•°æ®é›†ã€‚

---

## ğŸ“ HDF5 æ•°æ®é›†ç»“æ„

Isaac Lab ç”Ÿæˆçš„ HDF5 æ•°æ®é›†ç»“æ„å¦‚ä¸‹ï¼š

```
dataset.hdf5
â””â”€â”€ data/
    â”œâ”€â”€ demo_0/
    â”‚   â”œâ”€â”€ observations/
    â”‚   â”‚   â”œâ”€â”€ actions: (N, action_dim)
    â”‚   â”‚   â”œâ”€â”€ joint_pos: (N, num_joints)
    â”‚   â”‚   â”œâ”€â”€ joint_vel: (N, num_joints)
    â”‚   â”‚   â”œâ”€â”€ object: (N, object_dim)
    â”‚   â”‚   â”œâ”€â”€ eef_pos: (N, 3)
    â”‚   â”‚   â”œâ”€â”€ eef_quat: (N, 4)
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”œâ”€â”€ actions: (N, action_dim)
    â”‚   â”œâ”€â”€ rewards: (N,)
    â”‚   â””â”€â”€ dones: (N,)
    â”œâ”€â”€ demo_1/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ ...
```

### å…³é”®ç»“æ„

- **`data/`**: é¡¶å±‚ç»„ï¼ŒåŒ…å«æ‰€æœ‰æ¼”ç¤º
- **`demo_{i}/`**: ç¬¬ i ä¸ªæ¼”ç¤ºçš„æ•°æ®
- **`observations/`**: è§‚æµ‹æ•°æ®å­—å…¸ï¼ˆæ¯ä¸ªé”®å¯¹åº”ä¸€ä¸ªè§‚æµ‹ç±»å‹ï¼‰
- **`actions`**: åŠ¨ä½œæ•°ç»„ `[num_steps, action_dim]`
- **`rewards`**: å¥–åŠ±æ•°ç»„ `[num_steps,]`
- **`dones`**: ç»“æŸæ ‡å¿—æ•°ç»„ `[num_steps,]`

---

## ğŸ” æ–¹æ³• 1: ä½¿ç”¨ inspect_hdf5_dataset.pyï¼ˆæ¨èï¼‰

### æ£€æŸ¥æ•°æ®é›†ç»“æ„

```bash
python scripts/inspect_hdf5_dataset.py --dataset ./datasets/pick_place.hdf5
```

### æŸ¥çœ‹ç‰¹å®šæ¼”ç¤º

```bash
python scripts/inspect_hdf5_dataset.py \
    --dataset ./datasets/pick_place.hdf5 \
    --demo_idx 0 \
    --show_samples 10
```

### åŠ è½½ç‰¹å®šæ ·æœ¬

```bash
python scripts/inspect_hdf5_dataset.py \
    --dataset ./datasets/pick_place.hdf5 \
    --demo_idx 0 \
    --step_idx 5
```

---

## ğŸ“– æ–¹æ³• 2: ç›´æ¥ä½¿ç”¨ h5py è¯»å–

### åŸºæœ¬è¯»å–

```python
import h5py
import numpy as np

# æ‰“å¼€ HDF5 æ–‡ä»¶
with h5py.File('dataset.hdf5', 'r') as f:
    data_group = f['data']
    
    # è·å–æ‰€æœ‰æ¼”ç¤ºçš„é”®
    demo_keys = sorted([k for k in data_group.keys() if k.startswith('demo_')])
    print(f"Found {len(demo_keys)} demonstrations")
    
    # è¯»å–ç¬¬ä¸€ä¸ªæ¼”ç¤º
    demo_key = demo_keys[0]
    demo = data_group[demo_key]
    
    # è¯»å–è§‚æµ‹
    obs_dict = {}
    for key in demo['observations'].keys():
        obs_dict[key] = np.array(demo['observations'][key])
    
    # è¯»å–åŠ¨ä½œ
    actions = np.array(demo['actions'])
    
    # è¯»å–å¥–åŠ±å’Œç»“æŸæ ‡å¿—
    rewards = np.array(demo['rewards']) if 'rewards' in demo else None
    dones = np.array(demo['dones']) if 'dones' in demo else None
    
    print(f"Actions shape: {actions.shape}")
    print(f"Observations keys: {list(obs_dict.keys())}")
```

---

## ğŸ“– æ–¹æ³• 3: è¿­ä»£è¯»å–ï¼ˆå†…å­˜é«˜æ•ˆï¼‰

```python
import h5py
import numpy as np

def read_hdf5_iterative(dataset_path, obs_keys):
    """é€æ¼”ç¤ºè¯»å–æ•°æ®é›†ï¼ˆå†…å­˜é«˜æ•ˆï¼‰"""
    
    all_obs = []
    all_actions = []
    
    with h5py.File(dataset_path, 'r') as f:
        data_group = f['data']
        demo_keys = sorted([k for k in data_group.keys() if k.startswith('demo_')])
        
        for demo_key in demo_keys:
            demo = data_group[demo_key]
            
            # æå–è§‚æµ‹
            obs_list = []
            for key in obs_keys:
                if key in demo['observations']:
                    obs_val = np.array(demo['observations'][key])
                    # å±•å¹³ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if len(obs_val.shape) > 2:
                        obs_val = obs_val.reshape(obs_val.shape[0], -1)
                    obs_list.append(obs_val)
            
            # æ‹¼æ¥è§‚æµ‹
            obs_concat = np.concatenate(obs_list, axis=1)
            actions = np.array(demo['actions'])
            
            all_obs.append(obs_concat)
            all_actions.append(actions)
    
    # æ‹¼æ¥æ‰€æœ‰æ¼”ç¤º
    observations = np.concatenate(all_obs, axis=0)
    actions = np.concatenate(all_actions, axis=0)
    
    return observations, actions

# ä½¿ç”¨
obs_keys = ['joint_pos', 'joint_vel', 'eef_pos', 'eef_quat', ...]
observations, actions = read_hdf5_iterative('dataset.hdf5', obs_keys)
print(f"Observations: {observations.shape}, Actions: {actions.shape}")
```

---

## ğŸ“– æ–¹æ³• 4: PyTorch DataLoaderï¼ˆç”¨äºè®­ç»ƒï¼‰

```python
import torch
from torch.utils.data import Dataset, DataLoader
import h5py
import numpy as np

class HDF5Dataset(Dataset):
    """PyTorch Dataset for HDF5 files."""
    
    def __init__(self, dataset_path, obs_keys, normalize=True):
        self.dataset_path = dataset_path
        self.obs_keys = obs_keys
        self.normalize = normalize
        
        # é¢„åŠ è½½æ•°æ®ï¼ˆå°æ•°æ®é›†ï¼‰æˆ–å®ç°å»¶è¿ŸåŠ è½½ï¼ˆå¤§æ•°æ®é›†ï¼‰
        self._load_data()
    
    def _load_data(self):
        """åŠ è½½æ‰€æœ‰æ•°æ®"""
        all_obs = []
        all_actions = []
        
        with h5py.File(self.dataset_path, 'r') as f:
            data_group = f['data']
            demo_keys = sorted([k for k in data_group.keys() if k.startswith('demo_')])
            
            for demo_key in demo_keys:
                demo = data_group[demo_key]
                
                # æå–è§‚æµ‹
                obs_list = []
                for key in self.obs_keys:
                    if key in demo['observations']:
                        obs_val = np.array(demo['observations'][key])
                        if len(obs_val.shape) > 2:
                            obs_val = obs_val.reshape(obs_val.shape[0], -1)
                        obs_list.append(obs_val)
                
                obs_concat = np.concatenate(obs_list, axis=1)
                actions = np.array(demo['actions'])
                
                all_obs.append(obs_concat)
                all_actions.append(actions)
        
        self.observations = np.concatenate(all_obs, axis=0).astype(np.float32)
        self.actions = np.concatenate(all_actions, axis=0).astype(np.float32)
        
        # å½’ä¸€åŒ–
        if self.normalize:
            self.obs_mean = np.mean(self.observations, axis=0, keepdims=True)
            self.obs_std = np.std(self.observations, axis=0, keepdims=True) + 1e-8
    
    def __len__(self):
        return len(self.observations)
    
    def __getitem__(self, idx):
        obs = self.observations[idx]
        action = self.actions[idx]
        
        # å½’ä¸€åŒ–
        if self.normalize:
            obs = (obs - self.obs_mean.squeeze()) / self.obs_std.squeeze()
        
        return torch.from_numpy(obs), torch.from_numpy(action)

# åˆ›å»º DataLoader
obs_keys = ['joint_pos', 'joint_vel', 'eef_pos', ...]
dataset = HDF5Dataset('dataset.hdf5', obs_keys)
dataloader = DataLoader(dataset, batch_size=256, shuffle=True)

# ä½¿ç”¨
for obs_batch, action_batch in dataloader:
    # obs_batch: [batch_size, obs_dim]
    # action_batch: [batch_size, action_dim]
    pass
```

---

## ğŸ“– æ–¹æ³• 5: ä½¿ç”¨ Isaac Lab çš„ robomimic å·¥å…·ï¼ˆæ¨èç”¨äºè®­ç»ƒï¼‰

Isaac Lab çš„ `train.py` è„šæœ¬ä½¿ç”¨ robomimic çš„å·¥å…·å‡½æ•°ï¼š

```python
import robomimic.utils.file_utils as FileUtils
import robomimic.utils.train_utils as TrainUtils

# 1. è·å–æ•°æ®é›†å…ƒæ•°æ®
env_meta = FileUtils.get_env_metadata_from_dataset(dataset_path='dataset.hdf5')
shape_meta = FileUtils.get_shape_metadata_from_dataset(
    dataset_path='dataset.hdf5',
    all_obs_keys=['joint_pos', 'joint_vel', ...],
    verbose=True
)

# 2. åˆ›å»ºé…ç½®ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
from robomimic.config import Config
config = Config(...)
config.train.data = 'dataset.hdf5'
config.all_obs_keys = ['joint_pos', 'joint_vel', ...]

# 3. åŠ è½½è®­ç»ƒæ•°æ®
trainset, validset = TrainUtils.load_data_for_training(
    config,
    obs_keys=shape_meta["all_obs_keys"]
)

# 4. åˆ›å»º DataLoader
from torch.utils.data import DataLoader
train_loader = DataLoader(
    dataset=trainset,
    batch_size=256,
    shuffle=True,
    num_workers=4,
)
```

---

## ğŸ”§ å®Œæ•´ç¤ºä¾‹è„šæœ¬

### è„šæœ¬ 1: inspect_hdf5_dataset.py

æ£€æŸ¥æ•°æ®é›†ç»“æ„å’Œå†…å®¹ï¼š

```bash
python scripts/inspect_hdf5_dataset.py --dataset ./datasets/pick_place.hdf5
```

### è„šæœ¬ 2: read_hdf5_example.py

å±•ç¤ºä¸åŒçš„è¯»å–æ–¹æ³•ï¼š

```bash
python scripts/read_hdf5_example.py --dataset ./datasets/pick_place.hdf5 --method 4
```

---

## ğŸ¯ å¸¸è§è§‚æµ‹é”®å

æ ¹æ®ä½ çš„ç¯å¢ƒé…ç½®ï¼Œå¸¸è§çš„è§‚æµ‹é”®ååŒ…æ‹¬ï¼š

- **`actions`**: ä¸Šä¸€æ­¥åŠ¨ä½œï¼ˆç”¨äºå†å²ï¼‰
- **`joint_pos`**: å…³èŠ‚ä½ç½®
- **`joint_vel`**: å…³èŠ‚é€Ÿåº¦
- **`object`**: ç‰©ä½“çŠ¶æ€ï¼ˆä½ç½®ã€æ–¹å‘ç­‰ï¼‰
- **`object_positions`**: ç‰©ä½“ä½ç½®ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
- **`object_orientations`**: ç‰©ä½“æ–¹å‘ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
- **`eef_pos`**: æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®
- **`eef_quat`**: æœ«ç«¯æ‰§è¡Œå™¨å››å…ƒæ•°
- **`gripper_pos`**: å¤¹çˆªä½ç½®

---

## ğŸ’¡ æç¤º

### 1. å†…å­˜ç®¡ç†

- **å°æ•°æ®é›†**: ç›´æ¥åŠ è½½åˆ°å†…å­˜
- **å¤§æ•°æ®é›†**: ä½¿ç”¨è¿­ä»£è¯»å–æˆ–å»¶è¿ŸåŠ è½½
- **è®­ç»ƒ**: ä½¿ç”¨ PyTorch DataLoader çš„å¤šè¿›ç¨‹åŠ è½½

### 2. æ•°æ®å½’ä¸€åŒ–

åœ¨è®­ç»ƒå‰å½’ä¸€åŒ–è§‚æµ‹å’ŒåŠ¨ä½œï¼š

```python
# è§‚æµ‹å½’ä¸€åŒ–
obs_mean = np.mean(observations, axis=0)
obs_std = np.std(observations, axis=0) + 1e-8
normalized_obs = (observations - obs_mean) / obs_std

# åŠ¨ä½œå½’ä¸€åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
action_mean = np.mean(actions, axis=0)
action_std = np.std(actions, axis=0) + 1e-8
normalized_actions = (actions - action_mean) / action_std
```

### 3. æ•°æ®éªŒè¯

è¯»å–æ•°æ®åéªŒè¯å½¢çŠ¶å’ŒèŒƒå›´ï¼š

```python
print(f"Observations shape: {observations.shape}")
print(f"Actions shape: {actions.shape}")
print(f"Action range: [{np.min(actions):.3f}, {np.max(actions):.3f}]")
print(f"Observations range: [{np.min(observations):.3f}, {np.max(observations):.3f}]")
```

---

## ğŸ”— å‚è€ƒ

1. **Isaac Lab è®­ç»ƒè„šæœ¬**: `/mnt/ssd/IsaacLab/scripts/imitation_learning/robomimic/train.py`
2. **HDF5 å®˜æ–¹æ–‡æ¡£**: https://www.h5py.org/
3. **robomimic æ–‡æ¡£**: https://robomimic.github.io/

---

ç¥ä½ ä½¿ç”¨é¡ºåˆ©ï¼ğŸš€


